{
    "name": "root",
    "gauges": {
        "AttackBehavior.Policy.Entropy.mean": {
            "value": 0.9947460889816284,
            "min": 0.7026153206825256,
            "max": 0.9947460889816284,
            "count": 90
        },
        "AttackBehavior.Policy.Entropy.sum": {
            "value": 19831.2578125,
            "min": 3027.59033203125,
            "max": 19831.2578125,
            "count": 90
        },
        "AttackBehavior.Environment.EpisodeLength.mean": {
            "value": 46.117924528301884,
            "min": 44.16143497757847,
            "max": 47.10576923076923,
            "count": 90
        },
        "AttackBehavior.Environment.EpisodeLength.sum": {
            "value": 19554.0,
            "min": 3300.0,
            "max": 19696.0,
            "count": 90
        },
        "AttackBehavior.Step.mean": {
            "value": 19079962.0,
            "min": 17299980.0,
            "max": 19079962.0,
            "count": 90
        },
        "AttackBehavior.Step.sum": {
            "value": 19079962.0,
            "min": 17299980.0,
            "max": 19079962.0,
            "count": 90
        },
        "AttackBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.6189769506454468,
            "min": -0.6377757787704468,
            "max": -0.45692339539527893,
            "count": 90
        },
        "AttackBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": -262.44622802734375,
            "min": -273.397705078125,
            "max": -31.984638214111328,
            "count": 90
        },
        "AttackBehavior.Environment.CumulativeReward.mean": {
            "value": -1.0,
            "min": -1.0424528301886793,
            "max": -0.9976359338061466,
            "count": 90
        },
        "AttackBehavior.Environment.CumulativeReward.sum": {
            "value": -424.0,
            "min": -452.0,
            "max": -70.0,
            "count": 90
        },
        "AttackBehavior.Policy.ExtrinsicReward.mean": {
            "value": -1.0,
            "min": -1.0424528301886793,
            "max": -0.9976359338061466,
            "count": 90
        },
        "AttackBehavior.Policy.ExtrinsicReward.sum": {
            "value": -424.0,
            "min": -452.0,
            "max": -70.0,
            "count": 90
        },
        "AttackBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 90
        },
        "AttackBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 90
        },
        "AttackBehavior.Losses.PolicyLoss.mean": {
            "value": 0.01587058991426602,
            "min": 0.012785487330984325,
            "max": 0.02161213078070432,
            "count": 86
        },
        "AttackBehavior.Losses.PolicyLoss.sum": {
            "value": 0.01587058991426602,
            "min": 0.012785487330984325,
            "max": 0.02161213078070432,
            "count": 86
        },
        "AttackBehavior.Losses.ValueLoss.mean": {
            "value": 0.09373836629092694,
            "min": 0.09357432164251804,
            "max": 0.16869889833033086,
            "count": 86
        },
        "AttackBehavior.Losses.ValueLoss.sum": {
            "value": 0.09373836629092694,
            "min": 0.09357432164251804,
            "max": 0.16869889833033086,
            "count": 86
        },
        "AttackBehavior.Policy.LearningRate.mean": {
            "value": 0.0002,
            "min": 0.0002,
            "max": 0.0002,
            "count": 86
        },
        "AttackBehavior.Policy.LearningRate.sum": {
            "value": 0.0002,
            "min": 0.0002,
            "max": 0.0002,
            "count": 86
        },
        "AttackBehavior.Policy.Epsilon.mean": {
            "value": 0.15,
            "min": 0.15,
            "max": 0.15,
            "count": 86
        },
        "AttackBehavior.Policy.Epsilon.sum": {
            "value": 0.15,
            "min": 0.15,
            "max": 0.15,
            "count": 86
        },
        "AttackBehavior.Policy.Beta.mean": {
            "value": 0.003,
            "min": 0.003,
            "max": 0.003,
            "count": 86
        },
        "AttackBehavior.Policy.Beta.sum": {
            "value": 0.003,
            "min": 0.003,
            "max": 0.003,
            "count": 86
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1637214431",
        "python_version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\lukma\\AppData\\Local\\Programs\\Python\\Python38\\Scripts\\mlagents-learn attackBehavior.yaml --run-id=ppo --resume",
        "mlagents_version": "0.26.0",
        "mlagents_envs_version": "0.26.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.8.2+cu102",
        "numpy_version": "1.21.3",
        "end_time_seconds": "1637218215"
    },
    "total": 3783.5592706,
    "count": 1,
    "self": 0.005237100000613282,
    "children": {
        "run_training.setup": {
            "total": 0.11692979999999986,
            "count": 1,
            "self": 0.11692979999999986
        },
        "TrainerController.start_learning": {
            "total": 3783.4371036999996,
            "count": 1,
            "self": 1.4888610000034532,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.156835599999999,
                    "count": 1,
                    "self": 8.156835599999999
                },
                "TrainerController.advance": {
                    "total": 3773.619397799996,
                    "count": 74580,
                    "self": 1.4833883999340287,
                    "children": {
                        "env_step": {
                            "total": 3180.1467620000667,
                            "count": 74580,
                            "self": 2730.4127044000666,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 448.77914460000426,
                                    "count": 74580,
                                    "self": 6.878772399927755,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 441.9003722000765,
                                            "count": 112724,
                                            "self": 87.91003660015349,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 353.990335599923,
                                                    "count": 112724,
                                                    "self": 353.990335599923
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.9549129999958996,
                                    "count": 74579,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3774.7089810999714,
                                            "count": 74579,
                                            "is_parallel": true,
                                            "self": 1178.1288253999905,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0012277000000002758,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.0005207000000000406,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0007070000000002352,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.0007070000000002352
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 2596.578927999981,
                                                    "count": 74579,
                                                    "is_parallel": true,
                                                    "self": 19.13928330002227,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 25.34465239999221,
                                                            "count": 74579,
                                                            "is_parallel": true,
                                                            "self": 25.34465239999221
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 2490.6164090999678,
                                                            "count": 74579,
                                                            "is_parallel": true,
                                                            "self": 2490.6164090999678
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 61.47858319999852,
                                                            "count": 149158,
                                                            "is_parallel": true,
                                                            "self": 25.005872099970297,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 36.47271110002822,
                                                                    "count": 596632,
                                                                    "is_parallel": true,
                                                                    "self": 36.47271110002822
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 591.9892473999955,
                            "count": 74579,
                            "self": 2.865057700000193,
                            "children": {
                                "process_trajectory": {
                                    "total": 179.19430119999618,
                                    "count": 74579,
                                    "self": 178.57607039999567,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.6182308000005037,
                                            "count": 4,
                                            "self": 0.6182308000005037
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 409.92988849999915,
                                    "count": 87,
                                    "self": 328.12022129999553,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 81.8096672000036,
                                            "count": 3480,
                                            "self": 81.8096672000036
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 9.000000318337698e-07,
                    "count": 1,
                    "self": 9.000000318337698e-07
                },
                "TrainerController._save_models": {
                    "total": 0.17200840000032258,
                    "count": 1,
                    "self": 0.008287000000564149,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.16372139999975843,
                            "count": 1,
                            "self": 0.16372139999975843
                        }
                    }
                }
            }
        }
    }
}